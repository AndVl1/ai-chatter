name: Performance Tests

on:
  # –ó–∞–ø—É—Å–∫ –ø—Ä–∏ —Ä–µ–ª–∏–∑–Ω—ã—Ö —Ç–µ–≥–∞—Ö
  push:
    tags:
      - 'v*'
  # –ó–∞–ø—É—Å–∫ –≤—Ä—É—á–Ω—É—é
  workflow_dispatch:
    inputs:
      benchmark_duration:
        description: 'Benchmark duration (e.g., 30s, 5m)'
        required: false
        default: '30s'
      concurrent_requests:
        description: 'Number of concurrent requests'
        required: false
        default: '5'

env:
  GO_VERSION: '1.22.x'

jobs:
  performance-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Install benchmarking tools
        run: |
          go install golang.org/x/perf/cmd/benchstat@latest
          
      - name: Download dependencies
        run: go mod download

      - name: Build for performance testing
        run: |
          echo "üî® Building optimized binaries..."
          go build -ldflags="-s -w" -o notion-mcp-server cmd/notion-mcp-server/main.go
          go build -ldflags="-s -w" -o ai-chatter cmd/bot/main.go

      - name: Run Go benchmarks
        run: |
          echo "‚ö° Running Go benchmarks..."
          go test -bench=. -benchmem -count=3 ./... > benchmark-results.txt 2>&1 || true
          
          if [ -s benchmark-results.txt ]; then
            echo "üìä Benchmark results:"
            cat benchmark-results.txt
          else
            echo "‚ö†Ô∏è No benchmarks found - creating placeholder"
            echo "No benchmark functions found in the codebase" > benchmark-results.txt
          fi

      - name: Performance test - MCP connection speed
        if: ${{ env.NOTION_TOKEN != '' }}
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_TEST_PAGE_ID: ${{ secrets.NOTION_TEST_PAGE_ID }}
        run: |
          echo "üîó Testing MCP connection performance..."
          
          # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–π performance —Ç–µ—Å—Ç
          cat > perf_test.go << 'EOF'
          package main
          
          import (
            "context"
            "fmt"
            "time"
            "ai-chatter/internal/notion"
          )
          
          func main() {
            token := "${{ secrets.NOTION_TOKEN }}"
            if token == "" {
              fmt.Println("NOTION_TOKEN not set, skipping performance test")
              return
            }
            
            fmt.Println("üöÄ Starting MCP connection performance test...")
            
            // –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            start := time.Now()
            client := notion.NewMCPClient(token)
            err := client.Connect(context.Background(), token)
            connectionTime := time.Since(start)
            
            if err != nil {
              fmt.Printf("‚ùå Connection failed: %v\n", err)
              return
            }
            defer client.Close()
            
            fmt.Printf("‚úÖ Connection established in: %v\n", connectionTime)
            
            if connectionTime > 5*time.Second {
              fmt.Println("‚ö†Ô∏è Connection is slower than expected (>5s)")
            }
          }
          EOF
          
          if [ -n "$NOTION_TOKEN" ]; then
            go run perf_test.go
          else
            echo "‚ö†Ô∏è Skipping performance test - NOTION_TOKEN not configured"
          fi

      - name: Memory profiling
        run: |
          echo "üß† Running memory profiling..."
          
          # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã —Å memory profiling
          go test ./internal/notion -memprofile=mem.prof -run=TestMCPConnection -timeout=5m || true
          
          if [ -f mem.prof ]; then
            echo "üìä Memory profile generated"
            go tool pprof -text -alloc_space mem.prof > memory-analysis.txt
            echo "Memory analysis:"
            head -20 memory-analysis.txt
          else
            echo "‚ö†Ô∏è Memory profile not generated"
          fi

      - name: CPU profiling  
        run: |
          echo "‚ö° Running CPU profiling..."
          
          # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã —Å CPU profiling
          go test ./internal/notion -cpuprofile=cpu.prof -run=TestMCPConnection -timeout=5m || true
          
          if [ -f cpu.prof ]; then
            echo "üìä CPU profile generated"
            go tool pprof -text -cum cpu.prof > cpu-analysis.txt
            echo "CPU analysis:"
            head -20 cpu-analysis.txt
          else
            echo "‚ö†Ô∏è CPU profile not generated"
          fi

      - name: Concurrent request test
        if: ${{ env.NOTION_TOKEN != '' }}
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_TEST_PAGE_ID: ${{ secrets.NOTION_TEST_PAGE_ID }}
          CONCURRENT_REQUESTS: ${{ inputs.concurrent_requests || '5' }}
        run: |
          echo "üîÑ Testing concurrent requests (${CONCURRENT_REQUESTS} concurrent)..."
          
          # –°–æ–∑–¥–∞—ë–º concurrent —Ç–µ—Å—Ç
          cat > concurrent_test.go << 'EOF'
          package main
          
          import (
            "context"
            "fmt"
            "sync"
            "time"
            "ai-chatter/internal/notion"
          )
          
          func main() {
            token := "${{ secrets.NOTION_TOKEN }}"
            testPageID := "${{ secrets.NOTION_TEST_PAGE_ID }}"
            concurrent := ${{ inputs.concurrent_requests || '5' }}
            
            if token == "" || testPageID == "" {
              fmt.Println("Secrets not set, skipping concurrent test")
              return
            }
            
            fmt.Printf("üîÑ Starting %d concurrent MCP connections...\n", concurrent)
            
            var wg sync.WaitGroup
            start := time.Now()
            errors := make(chan error, concurrent)
            
            for i := 0; i < concurrent; i++ {
              wg.Add(1)
              go func(id int) {
                defer wg.Done()
                
                client := notion.NewMCPClient(token)
                err := client.Connect(context.Background(), token)
                if err != nil {
                  errors <- fmt.Errorf("client %d: %v", id, err)
                  return
                }
                defer client.Close()
                
                fmt.Printf("‚úÖ Client %d connected\n", id)
              }(i)
            }
            
            wg.Wait()
            close(errors)
            totalTime := time.Since(start)
            
            errorCount := 0
            for err := range errors {
              fmt.Printf("‚ùå %v\n", err)
              errorCount++
            }
            
            fmt.Printf("üìä Results: %d/%d successful in %v\n", concurrent-errorCount, concurrent, totalTime)
            
            if errorCount > 0 {
              fmt.Printf("‚ö†Ô∏è %d/%d connections failed\n", errorCount, concurrent)
            }
          }
          EOF
          
          if [ -n "$NOTION_TOKEN" ] && [ -n "$NOTION_TEST_PAGE_ID" ]; then
            timeout 60s go run concurrent_test.go || echo "Concurrent test completed/timed out"
          else
            echo "‚ö†Ô∏è Skipping concurrent test - secrets not configured"
          fi

      - name: Generate performance report
        if: always()
        run: |
          echo "üìã Generating performance report..."
          
          cat > performance-report.md << 'EOF'
          # ‚ö° Performance Test Report
          
          **Date:** $(date)
          **Commit:** ${{ github.sha }}
          **Tag:** ${{ github.ref_name }}
          **Go Version:** ${{ env.GO_VERSION }}
          
          ## Test Configuration
          - **Benchmark Duration:** ${{ inputs.benchmark_duration || '30s' }}
          - **Concurrent Requests:** ${{ inputs.concurrent_requests || '5' }}
          
          ## Results Summary
          EOF
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å
          if [ -f benchmark-results.txt ]; then
            echo "### Go Benchmarks" >> performance-report.md
            echo '```' >> performance-report.md
            cat benchmark-results.txt >> performance-report.md
            echo '```' >> performance-report.md
            echo "" >> performance-report.md
          fi
          
          # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –ø–∞–º—è—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
          if [ -f memory-analysis.txt ]; then
            echo "### Memory Analysis (Top Allocations)" >> performance-report.md
            echo '```' >> performance-report.md
            head -10 memory-analysis.txt >> performance-report.md
            echo '```' >> performance-report.md
            echo "" >> performance-report.md
          fi
          
          # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ CPU –µ—Å–ª–∏ –µ—Å—Ç—å
          if [ -f cpu-analysis.txt ]; then
            echo "### CPU Analysis (Top Functions)" >> performance-report.md
            echo '```' >> performance-report.md
            head -10 cpu-analysis.txt >> performance-report.md
            echo '```' >> performance-report.md
          fi
          
          echo "Report generated at $(date)"

      - name: Upload performance artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ github.run_number }}
          path: |
            performance-report.md
            benchmark-results.txt
            memory-analysis.txt
            cpu-analysis.txt
            *.prof
          retention-days: 90

      - name: Performance regression check
        if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v')
        run: |
          echo "üîç Checking for performance regressions..."
          
          # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ä–µ–ª–∏–∑–∞–º–∏
          # –ò—Å–ø–æ–ª—å–∑—É—è GitHub API –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
          
          echo "üìä Performance check completed"
          echo "üí° To detect regressions, compare with previous release artifacts"

package vibecoding

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"ai-chatter/internal/codevalidation"
	"ai-chatter/internal/llm"
)

// –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ MCP –∫–ª–∏–µ–Ω—Ç—É
var (
	globalSessionManager atomic.Value
	globalMCPClient      atomic.Value
)

// SetGlobalSessionManager —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π
func SetGlobalSessionManager(sm *SessionManager) {
	globalSessionManager.Store(sm)
}

// SetGlobalMCPClient —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π MCP –∫–ª–∏–µ–Ω—Ç
func SetGlobalMCPClient(client *VibeCodingMCPClient) {
	globalMCPClient.Store(client)
}

// getGlobalMCPClient –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π MCP –∫–ª–∏–µ–Ω—Ç
func getGlobalMCPClient() *VibeCodingMCPClient {
	if client, ok := globalMCPClient.Load().(*VibeCodingMCPClient); ok {
		return client
	}
	return nil
}

// VibeCodingSession –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –≤–∞–π–±–∫–æ–¥–∏–Ω–≥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
type VibeCodingSession struct {
	UserID         int64                              // ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è Telegram
	ChatID         int64                              // ID —á–∞—Ç–∞
	ProjectName    string                             // –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
	StartTime      time.Time                          // –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏
	Files          map[string]string                  // –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞: –∏–º—è -> —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
	GeneratedFiles map[string]string                  // –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
	ContainerID    string                             // ID Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
	Analysis       *codevalidation.CodeAnalysisResult // –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ (unified from validator)
	TestCommand    string                             // –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤
	Docker         *DockerAdapter                     // Docker –∞–¥–∞–ø—Ç–µ—Ä
	LLMClient      llm.Client                         // LLM –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫
	Context        *ProjectContextLLM                 // –°–∂–∞—Ç—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è LLM (LLM-generated)
	mutex          sync.RWMutex                       // –ú—å—é—Ç–µ–∫—Å –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–æ—Ç–æ–∫–æ–≤
}

// SessionManager —É–ø—Ä–∞–≤–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Å–µ—Å—Å–∏—è–º–∏ –≤–∞–π–±–∫–æ–¥–∏–Ω–≥–∞
type SessionManager struct {
	sessions  map[int64]*VibeCodingSession // –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –ø–æ UserID
	mutex     sync.RWMutex                 // –ú—å—é—Ç–µ–∫—Å –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–æ—Ç–æ–∫–æ–≤
	webServer *WebServer                   // –í–µ–±-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–µ—Å—Å–∏–π
}

// NewSessionManager —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π
func NewSessionManager() *SessionManager {
	sm := &SessionManager{
		sessions: make(map[int64]*VibeCodingSession),
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º –≤–µ–±-—Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É 8080
	sm.webServer = NewWebServer(sm, 8080)
	go func() {
		if err := sm.webServer.Start(); err != nil && err != http.ErrServerClosed {
			log.Printf("‚ùå Failed to start VibeCoding web server: %v", err)
		}
	}()

	return sm
}

// NewSessionManagerWithoutWebServer —Å–æ–∑–¥–∞–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –±–µ–∑ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞
func NewSessionManagerWithoutWebServer() *SessionManager {
	return &SessionManager{
		sessions: make(map[int64]*VibeCodingSession),
	}
}

// CreateSession —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –≤–∞–π–±–∫–æ–¥–∏–Ω–≥–∞
func (sm *SessionManager) CreateSession(userID, chatID int64, projectName string, files map[string]string, llmClient llm.Client) (*VibeCodingSession, error) {
	sm.mutex.Lock()
	defer sm.mutex.Unlock()

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
	if existingSession, exists := sm.sessions[userID]; exists {
		return nil, fmt.Errorf("—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %d —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è: %s", userID, existingSession.ProjectName)
	}

	// –°–æ–∑–¥–∞–µ–º Docker –∫–ª–∏–µ–Ω—Ç –∏ –∞–¥–∞–ø—Ç–µ—Ä
	var dockerManager codevalidation.DockerManager
	realDockerClient, err := codevalidation.NewDockerClient()
	if err != nil {
		log.Printf("‚ö†Ô∏è Docker not available, using mock client for vibecoding session")
		dockerManager = codevalidation.NewMockDockerClient()
	} else {
		dockerManager = realDockerClient
	}

	dockerAdapter := NewDockerAdapter(dockerManager)

	session := &VibeCodingSession{
		UserID:         userID,
		ChatID:         chatID,
		ProjectName:    projectName,
		StartTime:      time.Now(),
		Files:          make(map[string]string),
		GeneratedFiles: make(map[string]string),
		Docker:         dockerAdapter,
		LLMClient:      llmClient,
	}

	// –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
	for filename, content := range files {
		session.Files[filename] = content
	}

	sm.sessions[userID] = session
	log.Printf("üî• Created vibecoding session for user %d: %s", userID, projectName)

	return session, nil
}

// CreatedAt –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å MCP
func (s *VibeCodingSession) CreatedAt() time.Time {
	return s.StartTime
}

// GetSession –ø–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
func (sm *SessionManager) GetSession(userID int64) *VibeCodingSession {
	sm.mutex.RLock()
	defer sm.mutex.RUnlock()

	session, exists := sm.sessions[userID]
	if !exists {
		return nil
	}
	return session
}

// GetAllSessions –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏ (–¥–ª—è –∞–¥–º–∏–Ω–∫–∏)
func (sm *SessionManager) GetAllSessions() map[int64]*VibeCodingSession {
	sm.mutex.RLock()
	defer sm.mutex.RUnlock()

	// –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∫–∞—Ä—Ç—ã –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
	sessionsCopy := make(map[int64]*VibeCodingSession)
	for userID, session := range sm.sessions {
		sessionsCopy[userID] = session
	}
	return sessionsCopy
}

// EndSession –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Å–µ—Å—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
func (sm *SessionManager) EndSession(userID int64) error {
	sm.mutex.Lock()
	defer sm.mutex.Unlock()

	session, exists := sm.sessions[userID]
	if !exists {
		return fmt.Errorf("—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %d –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏", userID)
	}

	// –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã —Å–µ—Å—Å–∏–∏
	if err := session.Cleanup(); err != nil {
		log.Printf("‚ö†Ô∏è Error cleaning up session for user %d: %v", userID, err)
	}

	delete(sm.sessions, userID)
	log.Printf("üî• Ended vibecoding session for user %d: %s", userID, session.ProjectName)

	return nil
}

// HasActiveSession –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è
func (sm *SessionManager) HasActiveSession(userID int64) bool {
	sm.mutex.RLock()
	defer sm.mutex.RUnlock()

	_, exists := sm.sessions[userID]
	return exists
}

// GetActiveSessions –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π
func (sm *SessionManager) GetActiveSessions() int {
	sm.mutex.RLock()
	defer sm.mutex.RUnlock()

	return len(sm.sessions)
}

// SetupEnvironment –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ —Å –µ–¥–∏–Ω—ã–º LLM –∑–∞–ø—Ä–æ—Å–æ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
func (s *VibeCodingSession) SetupEnvironment(ctx context.Context) error {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	log.Printf("üî• Setting up environment for vibecoding session: %s", s.ProjectName)

	// –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: VibeCoding MCP —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ, –∫–ª–∏–µ–Ω—Ç—ã –ø–æ–¥–∫–ª—é—á–∞—é—Ç—Å—è –∫ –Ω–µ–º—É

	maxAttempts := 3
	var lastError error

	for attempt := 1; attempt <= maxAttempts; attempt++ {
		log.Printf("üî• Environment setup attempt %d/%d", attempt, maxAttempts)

		// 1. –í—ã–ø–æ–ª–Ω—è–µ–º –µ–¥–∏–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
		if err := s.analyzeProjectAndGenerateContext(ctx); err != nil {
			lastError = fmt.Errorf("project analysis and context generation failed: %w", err)
			log.Printf("‚ùå Attempt %d failed: %v", attempt, lastError)
			continue
		}

		// 2. –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
		containerID, err := s.Docker.CreateContainer(ctx, s.Analysis)
		if err != nil {
			lastError = fmt.Errorf("container creation failed: %w", err)
			log.Printf("‚ùå Attempt %d failed: %v", attempt, lastError)
			continue
		}
		s.ContainerID = containerID

		// 3. –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
		if err := s.Docker.CopyFilesToContainer(ctx, s.ContainerID, s.Files); err != nil {
			lastError = fmt.Errorf("file copying failed: %w", err)
			log.Printf("‚ùå Attempt %d failed: %v", attempt, lastError)
			// –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø—Ä–∏ –æ—à–∏–±–∫–µ
			s.Docker.RemoveContainer(ctx, s.ContainerID)
			s.ContainerID = ""
			continue
		}

		// 4. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
		if err := s.Docker.InstallDependencies(ctx, s.ContainerID, s.Analysis); err != nil {
			lastError = fmt.Errorf("dependency installation failed: %w", err)
			log.Printf("‚ùå Attempt %d failed: %v", attempt, lastError)

			// –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∏ –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
			if attempt < maxAttempts {
				log.Printf("üîß Analyzing error and trying to fix configuration...")
				if fixedAnalysis, fixErr := s.analyzeAndFixError(ctx, err, s.Analysis, attempt); fixErr == nil {
					s.Analysis = fixedAnalysis
					log.Printf("‚úÖ Configuration updated, retrying with new settings")
				} else {
					log.Printf("‚ö†Ô∏è Could not fix configuration: %v", fixErr)
				}
			}

			// –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø—Ä–∏ –æ—à–∏–±–∫–µ
			s.Docker.RemoveContainer(ctx, s.ContainerID)
			s.ContainerID = ""
			continue
		}

		// 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤
		s.TestCommand = s.generateTestCommand()

		// 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª—ã
		if s.Context != nil {
			if err := s.saveContextFiles(s.Context); err != nil {
				log.Printf("‚ö†Ô∏è Failed to save context files: %v", err)
				// –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É, —Ñ–∞–π–ª—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã
			} else {
				log.Printf("‚úÖ Generated compressed project context with %d files, %d/%d tokens used",
					len(s.Context.Files), s.Context.TokensUsed, s.Context.TokensLimit)
			}
		}

		log.Printf("‚úÖ Environment setup successful on attempt %d", attempt)
		return nil
	}

	return fmt.Errorf("environment setup failed after %d attempts: %w", maxAttempts, lastError)
}

// analyzeProjectAndGenerateContext –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ
func (s *VibeCodingSession) analyzeProjectAndGenerateContext(ctx context.Context) error {
	log.Printf("üìäüß† Analyzing VibeCoding project and generating context with %d files using LLM", len(s.Files))

	if s.LLMClient == nil {
		return fmt.Errorf("LLM client not available")
	}

	// –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
	systemPrompt := `You are an expert DevOps engineer and code analyst. Your task is to:

1. ANALYZE the project for environment setup (Docker image, dependencies, commands)
2. GENERATE a compressed project context for AI understanding

Provide a JSON response with this exact structure:
{
  "analysis": {
    "language": "primary programming language",
    "framework": "detected framework (if any)",
    "docker_image": "appropriate docker image:tag",
    "install_commands": ["list", "of", "install", "commands"],
    "validation_commands": ["list", "of", "validation", "commands"],
    "test_commands": ["list", "of", "test", "commands"],
    "working_dir": "working directory (usually /workspace)",
    "project_type": "type description",
    "dependencies": ["key", "dependencies"],
    "reasoning": "brief explanation of choices"
  },
  "context": {
    "description": "Brief project description (max 100 chars)",
    "language": "same as analysis.language",
    "structure": {
      "directories": [
        {"path": "dirname", "purpose": "directory purpose", "file_count": 0}
      ],
      "file_types": [
        {"extension": ".ext", "language": "Language", "count": 0}
      ]
    },
    "dependencies": ["extracted", "dependencies"],
    "files": {
      "path/to/file.ext": {
        "summary": "Brief file description",
        "key_elements": ["main", "functions", "classes"],
        "purpose": "File's role in project",
        "dependencies": ["other", "files"],
        "type": "file_type"
      }
    }
  }
}

IMPORTANT:
- Be specific about Docker images (use exact tags like golang:1.22, python:3.11-slim)
- Include complete install commands for the detected language/framework
- Generate meaningful file summaries focusing on architecture and key components
- Keep file summaries concise but informative
- Focus on the most important files first
- Extract real dependencies from package files (go.mod, package.json, requirements.txt)
`

	// –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞
	fileList := make([]string, 0, len(s.Files))
	fileContents := make(map[string]string)

	for filename, content := range s.Files {
		fileList = append(fileList, filename)
		// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç
		if len(content) > 1000 {
			fileContents[filename] = content[:1000] + "... (truncated)"
		} else {
			fileContents[filename] = content
		}
	}

	// –°–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
	userPrompt := fmt.Sprintf(`PROJECT: %s
TOTAL FILES: %d

FILE LIST:
%s

KEY FILE CONTENTS:
%s

Please analyze this project and generate both environment setup configuration and compressed context.
Focus on:
1. Detecting the correct language/framework and appropriate Docker setup
2. Extracting key architectural components and file purposes
3. Understanding dependencies and project structure
4. Creating concise but informative file summaries`,
		s.ProjectName,
		len(s.Files),
		strings.Join(fileList, "\n"),
		s.formatFileContentsForPrompt(fileContents))

	messages := []llm.Message{
		{Role: "system", Content: systemPrompt},
		{Role: "user", Content: userPrompt},
	}

	log.Printf("üß† Requesting combined analysis and context generation from LLM...")
	response, err := s.LLMClient.Generate(ctx, messages)
	if err != nil {
		return fmt.Errorf("failed to get combined analysis: %w", err)
	}

	// –ü–∞—Ä—Å–∏–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
	var combinedResult struct {
		Analysis struct {
			Language           string   `json:"language"`
			Framework          string   `json:"framework"`
			DockerImage        string   `json:"docker_image"`
			InstallCommands    []string `json:"install_commands"`
			ValidationCommands []string `json:"validation_commands"`
			TestCommands       []string `json:"test_commands"`
			WorkingDir         string   `json:"working_dir"`
			ProjectType        string   `json:"project_type"`
			Dependencies       []string `json:"dependencies"`
			Reasoning          string   `json:"reasoning"`
		} `json:"analysis"`
		Context struct {
			Description string `json:"description"`
			Language    string `json:"language"`
			Structure   struct {
				Directories []struct {
					Path      string `json:"path"`
					Purpose   string `json:"purpose"`
					FileCount int    `json:"file_count"`
				} `json:"directories"`
				FileTypes []struct {
					Extension string `json:"extension"`
					Language  string `json:"language"`
					Count     int    `json:"count"`
				} `json:"file_types"`
			} `json:"structure"`
			Dependencies []string `json:"dependencies"`
			Files        map[string]struct {
				Summary      string   `json:"summary"`
				KeyElements  []string `json:"key_elements"`
				Purpose      string   `json:"purpose"`
				Dependencies []string `json:"dependencies"`
				Type         string   `json:"type"`
			} `json:"files"`
		} `json:"context"`
	}

	if err := json.Unmarshal([]byte(response.Content), &combinedResult); err != nil {
		log.Printf("‚ö†Ô∏è Failed to parse combined analysis response: %v", err)
		log.Printf("Raw response: %s", response.Content[:min(500, len(response.Content))])
		return fmt.Errorf("failed to parse combined analysis response: %w", err)
	}

	// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞
	s.Analysis = &codevalidation.CodeAnalysisResult{
		Language:        combinedResult.Analysis.Language,
		Framework:       combinedResult.Analysis.Framework,
		DockerImage:     combinedResult.Analysis.DockerImage,
		InstallCommands: combinedResult.Analysis.InstallCommands,
		Commands:        combinedResult.Analysis.ValidationCommands,
		TestCommands:    combinedResult.Analysis.TestCommands,
		WorkingDir:      combinedResult.Analysis.WorkingDir,
		ProjectType:     combinedResult.Analysis.ProjectType,
		Dependencies:    combinedResult.Analysis.Dependencies,
		Reasoning:       combinedResult.Analysis.Reasoning,
	}

	// –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
	s.Context = &ProjectContextLLM{
		ProjectName:  s.ProjectName,
		Language:     combinedResult.Context.Language,
		GeneratedAt:  time.Now(),
		TotalFiles:   len(s.Files),
		Description:  combinedResult.Context.Description,
		Dependencies: combinedResult.Context.Dependencies,
		Files:        make(map[string]LLMFileContext),
		TokensLimit:  5000,
		Structure: ProjectStructure{
			Directories: make([]Directory, 0),
			FileTypes:   make([]FileType, 0),
		},
	}

	// –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞—Ç–∞–ª–æ–≥–æ–≤
	for _, dir := range combinedResult.Context.Structure.Directories {
		s.Context.Structure.Directories = append(s.Context.Structure.Directories, Directory{
			Path:      dir.Path,
			Purpose:   dir.Purpose,
			FileCount: dir.FileCount,
		})
	}

	// –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–∏–ø—ã —Ñ–∞–π–ª–æ–≤
	for _, ft := range combinedResult.Context.Structure.FileTypes {
		s.Context.Structure.FileTypes = append(s.Context.Structure.FileTypes, FileType{
			Extension: ft.Extension,
			Language:  ft.Language,
			Count:     ft.Count,
		})
	}

	// –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
	tokenEstimator := &TokenEstimator{}
	totalTokens := 0
	for filePath, fileInfo := range combinedResult.Context.Files {
		fileContext := LLMFileContext{
			Path:         filePath,
			Type:         fileInfo.Type,
			Size:         len(s.Files[filePath]),
			LastModified: time.Now(),
			Summary:      fileInfo.Summary,
			KeyElements:  fileInfo.KeyElements,
			Purpose:      fileInfo.Purpose,
			Dependencies: fileInfo.Dependencies,
			NeedsUpdate:  false,
		}

		// –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
		fileContext.TokensUsed = tokenEstimator.EstimateTokens(
			fileContext.Summary +
				strings.Join(fileContext.KeyElements, " ") +
				fileContext.Purpose)
		totalTokens += fileContext.TokensUsed

		s.Context.Files[filePath] = fileContext
	}
	s.Context.TokensUsed = totalTokens

	log.Printf("üî• Combined analysis complete: %s (%s)", s.Analysis.Language, s.Analysis.DockerImage)
	log.Printf("üì¶ Install commands: %v", s.Analysis.InstallCommands)
	log.Printf("‚ö° Validation commands: %v", s.Analysis.Commands)
	log.Printf("üß™ Test commands: %v", s.Analysis.TestCommands)
	log.Printf("üß† Generated context: %d files, %d tokens, '%s'", len(s.Context.Files), s.Context.TokensUsed, s.Context.Description)

	return nil
}

// analyzeProject –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É—è LLM (unified approach from validator.go) - DEPRECATED
func (s *VibeCodingSession) analyzeProject(ctx context.Context) error {
	log.Printf("üìä Analyzing VibeCoding project with %d files using LLM", len(s.Files))

	// –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∏–∑ CodeValidationWorkflow
	workflow := codevalidation.NewCodeValidationWorkflow(s.LLMClient, nil)

	analysis, err := workflow.AnalyzeProjectForVibeCoding(ctx, s.Files)
	if err != nil {
		return fmt.Errorf("failed to analyze project: %w", err)
	}

	s.Analysis = analysis
	log.Printf("üî• VibeCoding project analysis complete: %s (%s)", s.Analysis.Language, s.Analysis.DockerImage)
	log.Printf("üì¶ Install commands: %v", s.Analysis.InstallCommands)
	log.Printf("‚ö° Validation commands: %v", s.Analysis.Commands)

	return nil
}

// formatFileContentsForPrompt —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç
func (s *VibeCodingSession) formatFileContentsForPrompt(fileContents map[string]string) string {
	var result strings.Builder
	count := 0
	maxFiles := 10 // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ

	for filename, content := range fileContents {
		if count >= maxFiles {
			result.WriteString("... (and more files)\n")
			break
		}

		result.WriteString(fmt.Sprintf("\n=== %s ===\n", filename))
		result.WriteString(content)
		result.WriteString("\n")
		count++
	}

	return result.String()
}

// Note: Hardcoded language detection methods removed - now using unified LLM-based approach from validator.go

// generateTestCommand –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ LLM
func (s *VibeCodingSession) generateTestCommand() string {
	// –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ LLM –∞–Ω–∞–ª–∏–∑–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
	if len(s.Analysis.TestCommands) > 0 {
		log.Printf("üß™ Using test command from LLM analysis: %s", s.Analysis.TestCommands[0])
		return s.Analysis.TestCommands[0]
	}

	// Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –µ—Å–ª–∏ TestCommands –ø—É—Å—Ç—ã–µ
	for _, cmd := range s.Analysis.Commands {
		// –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ "test" –≤ –∫–æ–º–∞–Ω–¥–µ
		if strings.Contains(strings.ToLower(cmd), "test") {
			log.Printf("üß™ Found test-like command from validation commands: %s", cmd)
			return cmd
		}
	}

	// –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –∫–æ–º–∞–Ω–¥—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞–∫ —Ç–µ—Å—Ç
	if len(s.Analysis.Commands) > 0 {
		log.Printf("‚ö†Ô∏è No test command found, using first validation command as test: %s", s.Analysis.Commands[0])
		return s.Analysis.Commands[0]
	}

	log.Printf("‚ö†Ô∏è No commands available from LLM analysis, using fallback")
	return "echo 'No test command available from LLM analysis'"
}

// AddGeneratedFile –¥–æ–±–∞–≤–ª—è–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–µ—Å—Å–∏—é
func (s *VibeCodingSession) AddGeneratedFile(filename, content string) {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	s.GeneratedFiles[filename] = content
	log.Printf("üî• Added generated file to session: %s (%d bytes)", filename, len(content))
}

// GetAllFiles –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã (–∏—Å—Ö–æ–¥–Ω—ã–µ + —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
func (s *VibeCodingSession) GetAllFiles() map[string]string {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	allFiles := make(map[string]string)

	// –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
	for filename, content := range s.Files {
		allFiles[filename] = content
	}

	// –ö–æ–ø–∏—Ä—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
	for filename, content := range s.GeneratedFiles {
		allFiles[filename] = content
	}

	return allFiles
}

// Cleanup –æ—á–∏—â–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã —Å–µ—Å—Å–∏–∏
func (s *VibeCodingSession) Cleanup() error {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	if s.ContainerID != "" {
		ctx := context.Background()
		if err := s.Docker.RemoveContainer(ctx, s.ContainerID); err != nil {
			return fmt.Errorf("failed to remove container %s: %w", s.ContainerID, err)
		}
		s.ContainerID = ""
	}

	log.Printf("üî• Session cleanup completed")
	return nil
}

// ExecuteCommand –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—É –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ —Å–µ—Å—Å–∏–∏
func (s *VibeCodingSession) ExecuteCommand(ctx context.Context, command string) (*codevalidation.ValidationResult, error) {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	if s.ContainerID == "" {
		return nil, fmt.Errorf("session environment not set up")
	}

	// –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã
	tempAnalysis := &codevalidation.CodeAnalysisResult{
		Language:    s.Analysis.Language,
		DockerImage: s.Analysis.DockerImage,
		Commands:    []string{command},
		WorkingDir:  s.Analysis.WorkingDir,
	}

	return s.Docker.ExecuteValidation(ctx, s.ContainerID, tempAnalysis)
}

// ListFiles –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Å–µ—Å—Å–∏–∏
func (s *VibeCodingSession) ListFiles(ctx context.Context) ([]string, error) {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	var files []string
	for filename := range s.Files {
		files = append(files, filename)
	}
	for filename := range s.GeneratedFiles {
		files = append(files, filename+" (generated)")
	}

	return files, nil
}

// ReadFile —á–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
func (s *VibeCodingSession) ReadFile(ctx context.Context, filename string) (string, error) {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	// –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –æ–±—ã—á–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
	if content, exists := s.Files[filename]; exists {
		return content, nil
	}

	// –ü–æ—Ç–æ–º –≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
	if content, exists := s.GeneratedFiles[filename]; exists {
		return content, nil
	}

	return "", fmt.Errorf("file not found: %s", filename)
}

// WriteFile –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –≤ —Å–µ—Å—Å–∏—é
func (s *VibeCodingSession) WriteFile(ctx context.Context, filename, content string, generated bool) error {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	if generated {
		s.GeneratedFiles[filename] = content
	} else {
		s.Files[filename] = content
	}

	// –¢–∞–∫–∂–µ –∫–æ–ø–∏—Ä—É–µ–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
	if s.ContainerID != "" {
		files := map[string]string{filename: content}
		if err := s.Docker.CopyFilesToContainer(ctx, s.ContainerID, files); err != nil {
			log.Printf("‚ö†Ô∏è Failed to copy file to container: %v", err)
			// –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É, —Ñ–∞–π–ª –≤—Å–µ —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Å–µ—Å—Å–∏–∏
		}
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ –∏–Ω–∫—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ (–¥–ª—è LLM –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
	if filename != "PROJECT_CONTEXT.md" && s.Context != nil && s.LLMClient != nil {
		go func() {
			// –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–∫—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è LLM –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
			generator := NewLLMContextGenerator(s.LLMClient, 5000)
			ctx := context.Background()
			if err := generator.UpdateFileContext(ctx, s.Context, filename, content); err != nil {
				log.Printf("‚ö†Ô∏è Failed to update LLM context for file %s: %v", filename, err)
				// Fallback: –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
				if err := s.RefreshProjectContext(); err != nil {
					log.Printf("‚ö†Ô∏è Failed to refresh project context after file write: %v", err)
				}
			} else {
				log.Printf("‚úÖ Updated LLM context for file: %s", filename)
				// –û–±–Ω–æ–≤–ª—è–µ–º PROJECT_CONTEXT.md —Å –Ω–æ–≤—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
				contextMarkdown := s.generateContextMarkdown()
				s.GeneratedFiles["PROJECT_CONTEXT.md"] = contextMarkdown
			}
		}()
	}

	return nil
}

// RemoveFile —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ —Å–µ—Å—Å–∏–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
func (s *VibeCodingSession) RemoveFile(ctx context.Context, filename string) error {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	// –£–¥–∞–ª—è–µ–º –∏–∑ –æ–±—ã—á–Ω—ã—Ö –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
	deleted := false
	if _, exists := s.Files[filename]; exists {
		delete(s.Files, filename)
		deleted = true
	}
	if _, exists := s.GeneratedFiles[filename]; exists {
		delete(s.GeneratedFiles, filename)
		deleted = true
	}

	if !deleted {
		return fmt.Errorf("file not found: %s", filename)
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (—É–¥–∞–ª—è–µ–º –∏–∑ LLM –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
	if filename != "PROJECT_CONTEXT.md" && s.Context != nil && s.LLMClient != nil {
		go func() {
			generator := NewLLMContextGenerator(s.LLMClient, 5000)
			generator.RemoveFileContext(s.Context, filename)
			log.Printf("‚úÖ Removed file from LLM context: %s", filename)

			// –û–±–Ω–æ–≤–ª—è–µ–º PROJECT_CONTEXT.md
			contextMarkdown := s.generateContextMarkdown()
			s.GeneratedFiles["PROJECT_CONTEXT.md"] = contextMarkdown
		}()
	}

	log.Printf("üî• Removed file from session: %s", filename)
	return nil
}

// ValidateCode –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–æ–¥ —Ñ–∞–π–ª–∞
func (s *VibeCodingSession) ValidateCode(ctx context.Context, code, filename string) (*codevalidation.ValidationResult, error) {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	if s.ContainerID == "" {
		return nil, fmt.Errorf("session environment not set up")
	}

	// –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–∞–Ω–¥—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
	if len(s.Analysis.Commands) == 0 {
		return &codevalidation.ValidationResult{
			Success:  true,
			Output:   "No validation commands available",
			ExitCode: 0,
		}, nil
	}

	// –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
	tempAnalysis := &codevalidation.CodeAnalysisResult{
		Language:    s.Analysis.Language,
		DockerImage: s.Analysis.DockerImage,
		Commands:    s.Analysis.Commands,
		WorkingDir:  s.Analysis.WorkingDir,
	}

	return s.Docker.ExecuteValidation(ctx, s.ContainerID, tempAnalysis)
}

// GetSessionInfo –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Å—Å–∏–∏
func (s *VibeCodingSession) GetSessionInfo() map[string]interface{} {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	info := map[string]interface{}{
		"project_name":    s.ProjectName,
		"language":        s.Analysis.Language,
		"start_time":      s.StartTime,
		"files_count":     len(s.Files),
		"generated_count": len(s.GeneratedFiles),
		"test_command":    s.TestCommand,
		"container_id":    s.ContainerID,
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
	if s.Context != nil {
		info["context_available"] = true
		info["context_generated_at"] = s.Context.GeneratedAt
		info["context_total_files"] = s.Context.TotalFiles
		info["context_tokens_used"] = s.Context.TokensUsed
		info["context_tokens_limit"] = s.Context.TokensLimit
		info["context_files_count"] = len(s.Context.Files)
	} else {
		info["context_available"] = false
	}

	return info
}

// analyzeAndFixError –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
func (s *VibeCodingSession) analyzeAndFixError(ctx context.Context, setupError error, currentAnalysis *codevalidation.CodeAnalysisResult, attempt int) (*codevalidation.CodeAnalysisResult, error) {
	if s.LLMClient == nil {
		return nil, fmt.Errorf("LLM client not available for error analysis")
	}

	log.Printf("üîç Analyzing setup error on attempt %d: %v", attempt, setupError)

	// –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫
	systemPrompt := `You are an expert DevOps engineer specializing in fixing environment setup issues. 
Analyze the error and current project configuration, then suggest concrete fixes.

Your task:
1. Identify the root cause of the error
2. Suggest specific changes to docker image, install commands, or project configuration
3. For Go projects: Pay special attention to Go version requirements in go.mod files
4. For version conflicts: Suggest appropriate Docker images with correct tool versions
5. Always provide SPECIFIC alternative docker images and commands

Common issues and solutions:
- Go version conflicts: Use golang:1.21 or golang:1.22 images
- Python version issues: Use python:3.9-slim or python:3.11-slim
- Node.js version issues: Use node:18-alpine or node:20-alpine
- Missing system packages: Add apt-get install commands

Return your response as a JSON object with this exact schema:
{
  "analysis": "brief explanation of what went wrong and why",
  "root_cause": "specific root cause (e.g., 'go_version_mismatch', 'missing_dependency', 'wrong_docker_image')",
  "suggested_fixes": {
    "docker_image": "alternative docker image if needed (provide specific image:tag, not null)",
    "install_commands": ["updated install commands array with specific commands"],
    "working_dir": "updated working directory (or null to keep current)",
    "additional_setup": ["any additional setup commands if needed"],
    "pre_install_commands": ["commands to run before main install commands"]
  },
  "confidence": "high|medium|low",
  "retry_recommended": true
}`

	// –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
	errorContext := fmt.Sprintf(`ERROR DETAILS:
Error: %s

CURRENT CONFIGURATION:
Language: %s
Docker Image: %s
Install Commands: %s
Working Directory: %s
Project Type: %s

PROJECT FILES:
%s

PROJECT SPECIFIC DETAILS:
%s

ATTEMPT NUMBER: %d (max 3 attempts)

Please analyze this error and suggest fixes to make the environment setup succeed. 
Be very specific about Docker image versions and install commands.`,
		setupError.Error(),
		currentAnalysis.Language,
		currentAnalysis.DockerImage,
		strings.Join(currentAnalysis.InstallCommands, ", "),
		currentAnalysis.WorkingDir,
		currentAnalysis.ProjectType,
		s.getProjectFilesSummary(),
		s.getProjectSpecificDetails(currentAnalysis.Language),
		attempt)

	messages := []llm.Message{
		{Role: "system", Content: systemPrompt},
		{Role: "user", Content: errorContext},
	}

	log.Printf("üß† Requesting error analysis from LLM")

	response, err := s.LLMClient.Generate(ctx, messages)
	if err != nil {
		return nil, fmt.Errorf("failed to get error analysis: %w", err)
	}

	// –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
	var analysisResult struct {
		Analysis       string `json:"analysis"`
		RootCause      string `json:"root_cause"`
		SuggestedFixes struct {
			DockerImage        string   `json:"docker_image"`
			InstallCommands    []string `json:"install_commands"`
			WorkingDir         *string  `json:"working_dir"`
			AdditionalSetup    []string `json:"additional_setup"`
			PreInstallCommands []string `json:"pre_install_commands"`
		} `json:"suggested_fixes"`
		Confidence       string `json:"confidence"`
		RetryRecommended bool   `json:"retry_recommended"`
	}

	if err := json.Unmarshal([]byte(response.Content), &analysisResult); err != nil {
		log.Printf("‚ö†Ô∏è Failed to parse LLM error analysis response: %v", err)
		log.Printf("Raw response: %s", response.Content)
		return nil, fmt.Errorf("failed to parse error analysis response: %w", err)
	}

	log.Printf("üîß Error analysis: %s", analysisResult.Analysis)
	log.Printf("üéØ Root cause: %s (confidence: %s, retry: %v)", analysisResult.RootCause, analysisResult.Confidence, analysisResult.RetryRecommended)

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ª–∏ –ø–æ–≤—Ç–æ—Ä
	if !analysisResult.RetryRecommended {
		log.Printf("‚ùå LLM does not recommend retry for this error type")
		return nil, fmt.Errorf("error analysis suggests this issue cannot be fixed automatically: %s", analysisResult.Analysis)
	}

	// –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
	fixedAnalysis := &codevalidation.CodeAnalysisResult{
		Language:        currentAnalysis.Language,
		Framework:       currentAnalysis.Framework,
		Dependencies:    currentAnalysis.Dependencies,
		InstallCommands: make([]string, 0), // –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞
		Commands:        currentAnalysis.Commands,
		DockerImage:     currentAnalysis.DockerImage,
		ProjectType:     currentAnalysis.ProjectType,
		WorkingDir:      currentAnalysis.WorkingDir,
		Reasoning:       currentAnalysis.Reasoning + fmt.Sprintf(" | Fix attempt %d [%s]: %s", attempt, analysisResult.RootCause, analysisResult.Analysis),
	}

	// –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–π Docker –æ–±—Ä–∞–∑
	if analysisResult.SuggestedFixes.DockerImage != "" {
		fixedAnalysis.DockerImage = analysisResult.SuggestedFixes.DockerImage
		log.Printf("üì¶ Updated Docker image: %s (was: %s)", fixedAnalysis.DockerImage, currentAnalysis.DockerImage)
	}

	// –î–æ–±–∞–≤–ª—è–µ–º pre-install –∫–æ–º–∞–Ω–¥—ã —Å–Ω–∞—á–∞–ª–∞
	if len(analysisResult.SuggestedFixes.PreInstallCommands) > 0 {
		fixedAnalysis.InstallCommands = append(fixedAnalysis.InstallCommands, analysisResult.SuggestedFixes.PreInstallCommands...)
		log.Printf("üîß Added pre-install commands: %v", analysisResult.SuggestedFixes.PreInstallCommands)
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏
	if len(analysisResult.SuggestedFixes.InstallCommands) > 0 {
		fixedAnalysis.InstallCommands = append(fixedAnalysis.InstallCommands, analysisResult.SuggestedFixes.InstallCommands...)
		log.Printf("‚öôÔ∏è Updated install commands: %v", analysisResult.SuggestedFixes.InstallCommands)
	} else {
		// –ï—Å–ª–∏ –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω—ã –Ω–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–µ
		fixedAnalysis.InstallCommands = append(fixedAnalysis.InstallCommands, currentAnalysis.InstallCommands...)
		log.Printf("‚ôªÔ∏è Keeping original install commands: %v", currentAnalysis.InstallCommands)
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏
	if len(analysisResult.SuggestedFixes.AdditionalSetup) > 0 {
		fixedAnalysis.InstallCommands = append(fixedAnalysis.InstallCommands, analysisResult.SuggestedFixes.AdditionalSetup...)
		log.Printf("‚ûï Added additional setup commands: %v", analysisResult.SuggestedFixes.AdditionalSetup)
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
	if analysisResult.SuggestedFixes.WorkingDir != nil {
		fixedAnalysis.WorkingDir = *analysisResult.SuggestedFixes.WorkingDir
		log.Printf("üìÅ Updated working directory: %s", fixedAnalysis.WorkingDir)
	}

	return fixedAnalysis, nil
}

// getProjectFilesSummary –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
func (s *VibeCodingSession) getProjectFilesSummary() string {
	var summary strings.Builder
	fileCount := 0
	maxFiles := 10 // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

	for filename := range s.Files {
		if fileCount >= maxFiles {
			summary.WriteString("... and more files")
			break
		}
		summary.WriteString(fmt.Sprintf("- %s\n", filename))
		fileCount++
	}

	return summary.String()
}

// getProjectSpecificDetails –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫
func (s *VibeCodingSession) getProjectSpecificDetails(language string) string {
	var details strings.Builder

	switch language {
	case "Go":
		// –ò—â–µ–º go.mod —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–µ—Ä—Å–∏–∏ Go
		if goMod, exists := s.Files["go.mod"]; exists {
			details.WriteString("go.mod content (first 500 chars):\n")
			if len(goMod) > 500 {
				details.WriteString(goMod[:500])
				details.WriteString("\n... (truncated)")
			} else {
				details.WriteString(goMod)
			}
			details.WriteString("\n\n")

			// –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –≤–µ—Ä—Å–∏—é Go –∏–∑ go.mod
			if strings.Contains(goMod, "go 1.") {
				lines := strings.Split(goMod, "\n")
				for _, line := range lines {
					if strings.Contains(line, "go 1.") && !strings.HasPrefix(strings.TrimSpace(line), "//") {
						details.WriteString(fmt.Sprintf("DETECTED GO VERSION REQUIREMENT: %s\n", strings.TrimSpace(line)))
						break
					}
				}
			}
		} else {
			details.WriteString("No go.mod file found in project\n")
		}

	case "Python":
		// –ò—â–µ–º requirements.txt –∏–ª–∏ pyproject.toml
		if req, exists := s.Files["requirements.txt"]; exists {
			details.WriteString("requirements.txt content (first 300 chars):\n")
			if len(req) > 300 {
				details.WriteString(req[:300])
				details.WriteString("\n... (truncated)")
			} else {
				details.WriteString(req)
			}
			details.WriteString("\n\n")
		}

		if pyproject, exists := s.Files["pyproject.toml"]; exists {
			details.WriteString("pyproject.toml content (first 300 chars):\n")
			if len(pyproject) > 300 {
				details.WriteString(pyproject[:300])
				details.WriteString("\n... (truncated)")
			} else {
				details.WriteString(pyproject)
			}
			details.WriteString("\n\n")
		}

	case "JavaScript":
		// –ò—â–µ–º package.json
		if pkg, exists := s.Files["package.json"]; exists {
			details.WriteString("package.json content (first 500 chars):\n")
			if len(pkg) > 500 {
				details.WriteString(pkg[:500])
				details.WriteString("\n... (truncated)")
			} else {
				details.WriteString(pkg)
			}
			details.WriteString("\n\n")
		}
	}

	if details.Len() == 0 {
		details.WriteString(fmt.Sprintf("No specific configuration files found for %s project\n", language))
	}

	return details.String()
}

// startMCPServerInContainer –∑–∞–ø—É—Å–∫–∞–µ—Ç VibeCoding MCP —Å–µ—Ä–≤–µ—Ä –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
func (s *VibeCodingSession) startMCPServerInContainer(ctx context.Context) {
	if s.ContainerID == "" {
		log.Printf("‚ö†Ô∏è Cannot start MCP server: no container ID")
		return
	}

	log.Printf("üöÄ Starting VibeCoding MCP server in container %s", s.ContainerID)

	// –ö–æ–ø–∏—Ä—É–µ–º –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª MCP —Å–µ—Ä–≤–µ—Ä–∞ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
	mcpServerPath := "./cmd/vibecoding-mcp-server/vibecoding-mcp-server"
	copyCmd := fmt.Sprintf("docker cp %s %s:/workspace/vibecoding-mcp-server", mcpServerPath, s.ContainerID)

	if _, err := s.Docker.ExecuteValidation(ctx, s.ContainerID, &codevalidation.CodeAnalysisResult{
		Commands: []string{copyCmd},
	}); err != nil {
		log.Printf("‚ùå Failed to copy MCP server to container: %v", err)
		return
	}

	// –î–µ–ª–∞–µ–º —Ñ–∞–π–ª –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º
	chmodCmd := "chmod +x /workspace/vibecoding-mcp-server"
	if _, err := s.Docker.ExecuteValidation(ctx, s.ContainerID, &codevalidation.CodeAnalysisResult{
		Commands: []string{chmodCmd},
	}); err != nil {
		log.Printf("‚ùå Failed to make MCP server executable: %v", err)
		return
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä –≤ —Ñ–æ–Ω–µ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
	startCmd := "nohup /workspace/vibecoding-mcp-server > /tmp/mcp-server.log 2>&1 &"
	if _, err := s.Docker.ExecuteValidation(ctx, s.ContainerID, &codevalidation.CodeAnalysisResult{
		Commands: []string{startCmd},
	}); err != nil {
		log.Printf("‚ùå Failed to start MCP server in container: %v", err)
		return
	}

	log.Printf("‚úÖ VibeCoding MCP server started in container %s", s.ContainerID)
}

// generateProjectContext –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∂–∞—Ç—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
func (s *VibeCodingSession) generateProjectContext() error {
	log.Printf("üìã Generating LLM-based compressed project context...")

	// –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ª–∏–º–∏—Ç–æ–º —Ç–æ–∫–µ–Ω–æ–≤ (5000 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
	generator := NewLLMContextGenerator(s.LLMClient, 5000)

	// –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã (–∏—Å—Ö–æ–¥–Ω—ã–µ + —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
	allFiles := s.GetAllFiles()

	ctx := context.Background()
	context, err := generator.GenerateContext(ctx, s.ProjectName, allFiles)
	if err != nil {
		return fmt.Errorf("failed to generate LLM context: %w", err)
	}

	s.Context = context

	// –°–æ–∑–¥–∞–µ–º JSON –∏ Markdown —Ñ–∞–π–ª—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
	if err := s.saveContextFiles(context); err != nil {
		log.Printf("‚ö†Ô∏è Failed to save context files: %v", err)
	}

	log.Printf("‚úÖ Generated LLM project context: %d files, %d/%d tokens used",
		len(context.Files), context.TokensUsed, context.TokensLimit)

	return nil
}

// generateContextMarkdown –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ LLM-–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
func (s *VibeCodingSession) generateContextMarkdown() string {
	if s.Context == nil {
		return "# Project Context\n\nContext not available."
	}

	var md strings.Builder

	md.WriteString("# LLM-Generated Project Context\n\n")
	md.WriteString(fmt.Sprintf("**Generated:** %s\n", s.Context.GeneratedAt.Format("2006-01-02 15:04:05")))
	md.WriteString(fmt.Sprintf("**Project:** %s\n", s.Context.ProjectName))
	md.WriteString(fmt.Sprintf("**Language:** %s\n", s.Context.Language))
	md.WriteString(fmt.Sprintf("**Total Files:** %d\n", s.Context.TotalFiles))
	md.WriteString(fmt.Sprintf("**Tokens Used:** %d / %d\n\n", s.Context.TokensUsed, s.Context.TokensLimit))

	if s.Context.Description != "" {
		md.WriteString(fmt.Sprintf("**Description:** %s\n\n", s.Context.Description))
	}

	// Dependencies
	if len(s.Context.Dependencies) > 0 {
		md.WriteString("## Dependencies\n\n")
		for _, dep := range s.Context.Dependencies {
			md.WriteString(fmt.Sprintf("- %s\n", dep))
		}
		md.WriteString("\n")
	}

	// Project structure
	md.WriteString("## Project Structure\n\n")
	for _, dir := range s.Context.Structure.Directories {
		md.WriteString(fmt.Sprintf("- **%s** (%d files) - %s\n", dir.Path, dir.FileCount, dir.Purpose))
	}
	md.WriteString("\n")

	// File types
	if len(s.Context.Structure.FileTypes) > 0 {
		md.WriteString("### File Types\n\n")
		for _, ft := range s.Context.Structure.FileTypes {
			md.WriteString(fmt.Sprintf("- %s: %d files (%s)\n", ft.Extension, ft.Count, ft.Language))
		}
		md.WriteString("\n")
	}

	// LLM-generated file descriptions
	md.WriteString("## File Descriptions (LLM-Generated)\n\n")
	for filePath, fileContext := range s.Context.Files {
		md.WriteString(fmt.Sprintf("### %s\n", filePath))
		md.WriteString(fmt.Sprintf("**Type:** %s | **Size:** %d bytes | **Last Modified:** %s\n",
			fileContext.Type, fileContext.Size, fileContext.LastModified.Format("2006-01-02 15:04:05")))
		md.WriteString(fmt.Sprintf("**Tokens Used:** %d\n\n", fileContext.TokensUsed))

		if fileContext.Summary != "" {
			md.WriteString(fmt.Sprintf("**Summary:** %s\n\n", fileContext.Summary))
		}

		if fileContext.Purpose != "" {
			md.WriteString(fmt.Sprintf("**Purpose:** %s\n\n", fileContext.Purpose))
		}

		// Key elements
		if len(fileContext.KeyElements) > 0 {
			md.WriteString("**Key Elements:**\n")
			for _, element := range fileContext.KeyElements {
				md.WriteString(fmt.Sprintf("- %s\n", element))
			}
			md.WriteString("\n")
		}

		// Dependencies
		if len(fileContext.Dependencies) > 0 {
			md.WriteString("**File Dependencies:**\n")
			for _, dep := range fileContext.Dependencies {
				md.WriteString(fmt.Sprintf("- %s\n", dep))
			}
			md.WriteString("\n")
		}

		md.WriteString("---\n\n")
	}

	// Usage instructions
	md.WriteString("## Usage Instructions for LLM\n\n")
	md.WriteString(s.generateUsageInstructionsMarkdown())

	return md.String()
}

// saveContextFiles —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö (JSON, Markdown)
func (s *VibeCodingSession) saveContextFiles(projectContext *ProjectContextLLM) error {
	log.Printf("üíæ Saving context files to project root...")

	// 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –∫–æ–Ω—Ç–µ–∫—Å—Ç (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
	jsonContent, err := s.generateContextJSON(projectContext)
	if err != nil {
		return fmt.Errorf("failed to generate JSON context: %w", err)
	}

	workingDir := "."
	if s.Analysis != nil && s.Analysis.WorkingDir != "" {
		workingDir = s.Analysis.WorkingDir
	}

	jsonPath := filepath.Join(workingDir, "vibecoding-context.json")
	if err := s.writeFile(jsonPath, jsonContent); err != nil {
		return fmt.Errorf("failed to write JSON context: %w", err)
	}
	log.Printf("üíæ ‚úÖ JSON context saved: %s", jsonPath)

	// 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º Markdown –∫–æ–Ω—Ç–µ–∫—Å—Ç (—á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–π)
	mdContent := s.generateContextMarkdown()
	mdPath := filepath.Join(workingDir, "vibecoding-context.md")
	if err := s.writeFile(mdPath, mdContent); err != nil {
		return fmt.Errorf("failed to write Markdown context: %w", err)
	}
	log.Printf("üíæ ‚úÖ Markdown context saved: %s", mdPath)

	return nil
}

// generateContextJSON –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
func (s *VibeCodingSession) generateContextJSON(projectContext *ProjectContextLLM) (string, error) {
	log.Printf("üîÑ Generating universal JSON context...")

	// –°–æ–∑–¥–∞–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è JSON
	universalContext := map[string]interface{}{
		"metadata": map[string]interface{}{
			"project_name": projectContext.ProjectName,
			"language":     projectContext.Language,
			"generator":    "LLM",
			"version":      "1.0",
			"generated_at": projectContext.GeneratedAt.Format(time.RFC3339),
			"total_files":  projectContext.TotalFiles,
			"tokens_used":  projectContext.TokensUsed,
			"tokens_limit": projectContext.TokensLimit,
		},
		"description":  projectContext.Description,
		"dependencies": projectContext.Dependencies,
		"structure": map[string]interface{}{
			"directories": projectContext.Structure.Directories,
			"file_types":  projectContext.Structure.FileTypes,
		},
		"files":              make(map[string]interface{}),
		"usage_instructions": s.generateUsageInstructions(),
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
	filesData := make(map[string]interface{})
	for filePath, fileContext := range projectContext.Files {
		filesData[filePath] = map[string]interface{}{
			"path":          fileContext.Path,
			"type":          fileContext.Type,
			"size":          fileContext.Size,
			"last_modified": fileContext.LastModified.Format(time.RFC3339),
			"summary":       fileContext.Summary,
			"key_elements":  fileContext.KeyElements,
			"purpose":       fileContext.Purpose,
			"dependencies":  fileContext.Dependencies,
			"tokens_used":   fileContext.TokensUsed,
			"needs_update":  fileContext.NeedsUpdate,
		}
	}
	universalContext["files"] = filesData

	// –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –≤ JSON —Å –∫—Ä–∞—Å–∏–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
	jsonBytes, err := json.MarshalIndent(universalContext, "", "  ")
	if err != nil {
		return "", fmt.Errorf("failed to marshal JSON: %w", err)
	}

	log.Printf("üîÑ ‚úÖ JSON context generated: %d bytes", len(jsonBytes))
	return string(jsonBytes), nil
}

// writeFile –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Ñ–∞–π–ª
func (s *VibeCodingSession) writeFile(filePath, content string) error {
	// –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
	dir := filepath.Dir(filePath)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return fmt.Errorf("failed to create directory %s: %w", dir, err)
	}

	// –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
	if err := os.WriteFile(filePath, []byte(content), 0644); err != nil {
		return fmt.Errorf("failed to write file %s: %w", filePath, err)
	}

	return nil
}

// GetProjectContext –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞
func (s *VibeCodingSession) GetProjectContext() *ProjectContextLLM {
	s.mutex.RLock()
	defer s.mutex.RUnlock()
	return s.Context
}

// RefreshProjectContext –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
func (s *VibeCodingSession) RefreshProjectContext() error {
	log.Printf("üîÑ Refreshing LLM project context...")

	// –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
	// –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º mutex –∑–¥–µ—Å—å, —Ç–∞–∫ –∫–∞–∫ analyzeProjectAndGenerateContext –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
	ctx := context.Background()
	if err := s.analyzeProjectAndGenerateContext(ctx); err != nil {
		return fmt.Errorf("failed to refresh LLM context using unified analysis: %w", err)
	}

	log.Printf("‚úÖ LLM project context refreshed successfully")
	return nil
}

// countTotalKeyElements –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –ø—Ä–æ–µ–∫—Ç–µ (LLM –∫–æ–Ω—Ç–µ–∫—Å—Ç)
func (s *VibeCodingSession) countTotalKeyElements() int {
	if s.Context == nil {
		return 0
	}

	total := 0
	for _, file := range s.Context.Files {
		total += len(file.KeyElements)
	}
	return total
}

// countTotalFiles –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ LLM –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
func (s *VibeCodingSession) countTotalFiles() int {
	if s.Context == nil {
		return 0
	}

	return len(s.Context.Files)
}

// ValidateAndFixTests –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –ø—Ä–æ—Ö–æ–¥—è—Ç
func (s *VibeCodingSession) ValidateAndFixTests(ctx context.Context, testFiles []string) error {
	const maxAttempts = 3

	s.mutex.Lock()
	defer s.mutex.Unlock()

	log.Printf("üß™ Starting test validation for %d test files", len(testFiles))

	for _, testFile := range testFiles {
		log.Printf("üîç Validating test file: %s", testFile)

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–µ—Å—Ç–æ–º
		if !s.isTestFile(testFile) {
			log.Printf("‚è≠Ô∏è Skipping non-test file: %s", testFile)
			continue
		}

		// –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
		for attempt := 1; attempt <= maxAttempts; attempt++ {
			log.Printf("üß™ Running test validation attempt %d/%d for %s", attempt, maxAttempts, testFile)

			// –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
			result, err := s.ExecuteCommand(ctx, s.buildTestCommand(testFile))
			if err != nil {
				log.Printf("‚ùå Failed to execute test command: %v", err)
				return fmt.Errorf("failed to execute test for %s: %w", testFile, err)
			}

			// –ï—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ñ–∞–π–ª—É
			if result.Success && result.ExitCode == 0 {
				log.Printf("‚úÖ Test %s passed on attempt %d", testFile, attempt)
				break
			}

			// –ï—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å –∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
			if attempt < maxAttempts {
				log.Printf("‚ùå Test %s failed on attempt %d (exit code: %d), requesting fixes...", testFile, attempt, result.ExitCode)

				if err := s.requestTestFix(ctx, testFile, result.Output); err != nil {
					log.Printf("‚ö†Ô∏è Failed to request test fix: %v", err)
					continue // –ü–æ–ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ –±–µ–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
				}
			} else {
				// –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–ª
				log.Printf("‚ùå Test %s failed after %d attempts (final exit code: %d)", testFile, maxAttempts, result.ExitCode)
				return fmt.Errorf("test %s failed after %d attempts: %s", testFile, maxAttempts, result.Output)
			}
		}
	}

	log.Printf("‚úÖ All test files validated successfully")
	return nil
}

// isTestFile –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Ç–µ—Å—Ç–æ–º
func (s *VibeCodingSession) isTestFile(filename string) bool {
	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –∏–º–µ–Ω
	lowerName := strings.ToLower(filename)

	// –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
	testPatterns := []string{
		"test_", "_test.", "test.", ".test.",
		"spec_", "_spec.", ".spec.",
		"__test__", "__tests__",
	}

	for _, pattern := range testPatterns {
		if strings.Contains(lowerName, pattern) {
			return true
		}
	}

	// –Ø–∑—ã–∫–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
	if s.Analysis != nil {
		switch strings.ToLower(s.Analysis.Language) {
		case "go":
			return strings.HasSuffix(lowerName, "_test.go")
		case "python":
			return strings.HasPrefix(lowerName, "test_") || strings.HasSuffix(lowerName, "_test.py")
		case "javascript", "typescript", "node.js":
			return strings.Contains(lowerName, ".test.") || strings.Contains(lowerName, ".spec.") || strings.Contains(lowerName, "__tests__")
		case "java":
			return strings.HasSuffix(lowerName, "test.java") || strings.HasSuffix(lowerName, "tests.java")
		}
	}

	return false
}

// buildTestCommand —Å–æ–∑–¥–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
func (s *VibeCodingSession) buildTestCommand(testFile string) string {
	if s.TestCommand == "" {
		return fmt.Sprintf("echo 'No test command configured for %s'", testFile)
	}

	// –ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä, –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ
	if strings.Contains(s.TestCommand, "%s") || strings.Contains(s.TestCommand, "{file}") {
		command := strings.ReplaceAll(s.TestCommand, "{file}", testFile)
		return fmt.Sprintf(command, testFile)
	}

	// –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —è–∑—ã–∫–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –∫ –∫–æ–º–∞–Ω–¥–µ
	if s.Analysis != nil {
		switch strings.ToLower(s.Analysis.Language) {
		case "go":
			return fmt.Sprintf("go test -v %s", testFile)
		case "python":
			return fmt.Sprintf("python -m pytest %s -v", testFile)
		case "javascript", "node.js":
			return fmt.Sprintf("npm test -- %s", testFile)
		}
	}

	// –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—â—É—é –∫–æ–º–∞–Ω–¥—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
	return s.TestCommand
}

// getMCPToolsInfo –ø–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ MCP –∏ —Å–ø–∏—Å–æ–∫ —Ç—É–ª–æ–≤
func (s *VibeCodingSession) getMCPToolsInfo() (available bool, tools []string) {
	// –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç—É–ª–æ–≤ —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π
	if sessionManager, exists := globalSessionManager.Load().(*SessionManager); exists && sessionManager != nil {
		if mcpClient := getGlobalMCPClient(); mcpClient != nil {
			ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
			defer cancel()

			if toolList, err := mcpClient.GetAvailableTools(ctx); err == nil && len(toolList) > 0 {
				log.Printf("‚úÖ MCP server available with %d tools: %v", len(toolList), toolList)
				return true, toolList
			} else {
				log.Printf("‚ö†Ô∏è MCP server unavailable: %v", err)
			}
		} else {
			log.Printf("‚ö†Ô∏è MCP client not initialized")
		}
	} else {
		log.Printf("‚ö†Ô∏è Session manager not available")
	}

	log.Printf("üîß MCP server is not available - context will not include MCP instructions")
	return false, nil
}

// getMCPToolsList –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö MCP —Ç—É–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
func (s *VibeCodingSession) getMCPToolsList() []string {
	available, tools := s.getMCPToolsInfo()
	if available {
		return tools
	}

	// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ MCP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
	return []string{}
}

// generateUsageInstructions —Å–æ–∑–¥–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –¥–ª—è JSON –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
func (s *VibeCodingSession) generateUsageInstructions() map[string]interface{} {
	mcpAvailable, mcpTools := s.getMCPToolsInfo()

	if mcpAvailable {
		return map[string]interface{}{
			"description":   "LLM-generated compressed project context with token budgeting and MCP tool access",
			"mcp_available": true,
			"mcp_tools":     mcpTools,
			"notes": []string{
				"Context is generated by LLM and provides high-level descriptions",
				"Use MCP tools to access actual file contents for implementation",
				"Context is token-limited and may not include all files due to budget constraints",
				"For large files, LLM can request content through MCP tools on-demand",
			},
		}
	} else {
		return map[string]interface{}{
			"description":   "LLM-generated compressed project context with token budgeting (MCP not available)",
			"mcp_available": false,
			"notes": []string{
				"Context is generated by LLM and provides high-level descriptions",
				"MCP server is not available - work only with provided context information",
				"Context is token-limited and may not include all files due to budget constraints",
				"File access is limited to information provided in this context",
			},
		}
	}
}

// generateUsageInstructionsMarkdown —Å–æ–∑–¥–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –¥–ª—è Markdown –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
func (s *VibeCodingSession) generateUsageInstructionsMarkdown() string {
	mcpAvailable, mcpTools := s.getMCPToolsInfo()

	var md strings.Builder

	if mcpAvailable {
		md.WriteString("This is an LLM-generated compressed project context with token budgeting and MCP tool access.\n\n")
		md.WriteString("**Available MCP Tools:**\n")
		for i, tool := range mcpTools {
			md.WriteString(fmt.Sprintf("%d. **%s**\n", i+1, tool))
		}
		md.WriteString("\n**Important Notes:**\n")
		md.WriteString("- This context is generated by an LLM and provides high-level descriptions\n")
		md.WriteString("- Use MCP tools to access actual file contents for implementation\n")
		md.WriteString("- Context is token-limited and may not include all files due to budget constraints\n")
		md.WriteString("- For large files, LLM can request content through MCP tools on-demand\n")
	} else {
		md.WriteString("This is an LLM-generated compressed project context with token budgeting.\n\n")
		md.WriteString("**‚ö†Ô∏è MCP Server Not Available**\n")
		md.WriteString("MCP tools are not accessible in this session. Work only with the provided context information.\n\n")
		md.WriteString("**Important Notes:**\n")
		md.WriteString("- This context is generated by an LLM and provides high-level descriptions\n")
		md.WriteString("- MCP server is not available - work only with provided context information\n")
		md.WriteString("- Context is token-limited and may not include all files due to budget constraints\n")
		md.WriteString("- File access is limited to information provided in this context\n")
	}

	return md.String()
}

// requestTestFix –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–ª–∏–≤—à–µ–≥–æ—Å—è —Ç–µ—Å—Ç–∞ —É LLM
func (s *VibeCodingSession) requestTestFix(ctx context.Context, testFile string, errorOutput string) error {
	log.Printf("üîß Requesting LLM to fix failing test: %s", testFile)

	// –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–µ—Å—Ç–∞
	testContent, exists := s.GeneratedFiles[testFile]
	if !exists {
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –æ–±—ã—á–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
		testContent, exists = s.Files[testFile]
		if !exists {
			return fmt.Errorf("test file %s not found", testFile)
		}
	}

	// –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
	prompt := fmt.Sprintf(`–¢–µ—Å—Ç –Ω–µ –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É. –ù—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏.

**–§–∞–π–ª —Ç–µ—Å—Ç–∞:** %s

**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–µ—Å—Ç–∞:**
%s

**–û—à–∏–±–∫–∏ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏:**
%s

**–ó–∞–¥–∞—á–∞:** –ò—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–µ—Å—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞–ª. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ —Ç–µ—Å—Ç–∞ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
1. –°–æ—Ö—Ä–∞–Ω–∏ –∏—Å—Ö–æ–¥–Ω—É—é –ª–æ–≥–∏–∫—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
2. –ò—Å–ø—Ä–∞–≤—å —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
3. –ò—Å–ø—Ä–∞–≤—å –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏/–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏  
4. –£–±–µ–¥–∏—Å—å —á—Ç–æ —Ç–µ—Å—Ç –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –Ω—É–∂–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
5. –í–æ–∑–≤—Ä–∞—â–∞–π —Ç–æ–ª—å–∫–æ –∫–æ–¥ –±–µ–∑ markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è`, testFile, testContent, errorOutput)

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
	messages := []llm.Message{
		{Role: "system", Content: "–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —Ç–µ—Å—Ç–æ–≤. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –∫–æ–¥–æ–º."},
		{Role: "user", Content: prompt},
	}

	response, err := s.LLMClient.Generate(ctx, messages)
	if err != nil {
		return fmt.Errorf("failed to get LLM response for test fix: %w", err)
	}

	// –ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥
	fixedCode := strings.TrimSpace(response.Content)

	// –£–±–∏—Ä–∞–µ–º markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
	if strings.HasPrefix(fixedCode, "```") {
		lines := strings.Split(fixedCode, "\n")
		if len(lines) > 2 {
			// –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫–∏ —Å ```
			fixedCode = strings.Join(lines[1:len(lines)-1], "\n")
		}
	}

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç
	s.GeneratedFiles[testFile] = fixedCode
	log.Printf("‚úÖ Test %s has been fixed by LLM", testFile)

	return nil
}
